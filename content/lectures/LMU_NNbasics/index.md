---
title: Math Primer and Neural Network Basics, LMU 2019-
# summary: Including fundamental topics such as MLE, optimization and a brief history of NN. 
# tags:
# - Deep Learning
date: "2021-11-11T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: "" 

links: "" 
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---

I give this guest lecture as part of ["Deep Learning and AI"](https://www.dbs.ifi.lmu.de/cms/studium_lehre/lehre_master/deep1920/index.html) since winter semester 2019, at LMU Munich for master students in computer science and similar majors. 
The major topics of this lecture include
- Recapping a few topics in probability theory that are most relevant for DL: MLE and MAE. 
- Recapping optimization methods, gradien-free, first- and second-gradient methods. 
- Giving an introduction to automatic differentiation. 
- Giving a *over-simplified* intro to the challenges and solutions in the course of NN's history.

{{% staticref "uploads/LMU_2021_MathPrimer.pdf" %}}The complete lecture slides.{{% /staticref %}}